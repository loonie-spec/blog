<!doctype html>

<html lang="en">

<!--
  Apply head only for dev environment, this is required for jekyll to
  insert livereload scripts
-->

  <head>



  <meta charset="utf-8">


<title>A Study of text mining - Loonie Park</title>

<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

<!-- Define a description for better SEO result -->
<meta name="description" content="My visual data story 그래프로 보는 이전과 달라진 한국 was published in BBC’s Korean Service on 11 May 2020. This post covers techniques and approaches applied to text mining and visualising the data. Since a new coronavirus outbreak was reported...">

<!-- Cheome Web App theme color -->
<meta name="theme-color" content="#ff00b4">

<!-- Feed URL -->
<link rel="alternate" href="/feed.xml" type="application/atom+xml">

<!-- Site icons -->
<link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="icon" href="/favicon.png" type="image/png"><link rel="icon" href="/favicon.svg?assets-inline-assets-keep" sizes="any" type="image/svg+xml"><link rel="mask-icon" href="/mask-icon.svg" color="#ff00b4">

<!-- Chrome Web App manifest -->
<link rel="manifest" href="/manifest.json">

<!-- Main CSS -->
<link rel="stylesheet" href="/assets/themes/curtana/css/app.css?assets-inline">

<!-- Canonical links, avoid duplicate content problems -->
<link rel="canonical" href="http://0.0.0.0:4321/textmining.html">

<!-- DNS prefetching for static files -->


<!-- Head hooks -->



  </head>

<!-- Open Graph and Twitter Cards support -->
<meta property="og:type" content="article">
<meta property="og:site_name" content="Loonie Park">
<meta property="og:title" content="A Study of text mining">
<meta property="og:url" content="http://0.0.0.0:4321/textmining.html">
<meta property="og:description" content="My visual data story 그래프로 보는 이전과 달라진 한국 was published in BBC’s Korean Service on 11 May 2020. This post covers techniques and approaches applied to text mining and visualising the data. Since a new coronavirus outbreak was reported...">
<meta property="og:image" content="https://user-images.githubusercontent.com/56850104/83661529-2ae15080-a5be-11ea-8a1e-e1e11909b2d6.png">

<meta name="twitter:card" content="summary_large_image">


  <meta name="twitter:site" content="@sparanoid">



  <meta name="twitter:creator" content="@ParkLoonie">



  <meta property="article:published_time" content="2020-05-25T00:00:00+01:00">
  <meta property="article:modified_time" content="2020-07-02T14:42:08+01:00">
  <meta name="twitter:label1" value="Words">
  <meta name="twitter:data1" value="733 words">
  <meta name="twitter:label2" value="Reading time">
  <meta name="twitter:data2" value="3 mins">

<!-- Post specified styles -->
<style data-assets-inline>
  :root {
    

    

    

    
  }
  @media (prefers-color-scheme: dark) {
    :root {
      --text-color-l: 95%;
      --bg-color-l: 14%;
      --bg-color-s: 2%;
      --code-color-l: calc(var(--link-color-l) * 1.3);
    }
  }
  

  body {
    
  }

  
  
    
</style>
<!-- Main navigation with current page / categoriy highlighted -->
<nav class="navigation">
  <ul>
    <li >
        <a href="/">Loonie Park</a>
      </li>
    <li >
        <a href="/news/">News</a>
      </li>
    <li >
        <a href="/about/">About</a>
      </li>
    
  </ul>
</nav>
<!-- Main content wrap -->
<main class="content " role=main>
  <!-- Post-wide custom CSS -->


<!-- Article wrapper, limit width -->
<article lang="en">

  <!-- Post title -->
  <header style="     ">

    <h1 class="" title="A Study of text mining" data-title="A Study of text mining">
      A Study of text mining<span class="dot dot--post"> </span>
    </h1>

    
      <small>
        on <time datetime="2020-05-25T00:00:00+01:00">May 25, 2020</time>
      </small>
    

    

  </header>

  <!-- Post content -->
  <div class="post-content">
    <p>My visual data story <a href="https://www.bbc.com/korean/news-52601647">그래프로 보는 이전과 달라진 한국</a> was published in BBC’s Korean Service on 11 May 2020. This post covers techniques and approaches applied to text mining and visualising the data.</p>

<p>Since a new coronavirus outbreak was reported in Wuhan on 31 December 2019 for the first time, the outbreak has been all over the media. My focus is on the Korean media’s coverage of the corona crisis and visualising it.</p>

<p>The process is broken down into three stages:</p>

<p><em>1 Web Scraping</em>
<em>2 Natural Language Processing</em>
<em>3 Visualising</em></p>

<h1 id="1-web-scraping">1 Web Scraping</h1>

<p>Using the news search function of Naver News<sup id="a1"><a href="https://www.bbc.com/korean/news-52601647">1</a></sup> I collected news articles by keyword ‘Corona19(코로나19 in Korean)’ and by date from 20 Jan 2020 to 30 April 2020.</p>

<p>The search keyword Corona19 is a common name that Korean media call Covid-19. I set the date range from 20 January, the day the first confirmed case was announced on in Korea. Then, I scrapped the website every 10 days.</p>

<p>There are three ways to scrape news articles from Naver News on R:
rvest(R package), Naver Open API, N2H4<sup id="a2"><a href="https://public.flourish.studio/visualisation/2576893">2</a></sup> (R package)</p>

<p>‘rvest’ is the most reliable package I can use to crawl the website for a specific date range.</p>

<h1 id="2-natural-language-processing">2 Natural Language Processing</h1>

<p>The first step to analyse articles was to break down the text into separate sentences. In this study, the Korean morphological analyser KoNLP was used for morpheme analysis. KoNLP is the only Korean natural language processing toolkit on R. With the SimplePos22 function of KoNLP I was able to extract nouns from the news articles and POS tagging.</p>

<p>The most complex part was identifying stop words. KoNLP can flag and filter them out by checking a hardcoded list of known stop words, as in the code below.
I could also use the buildDictionary function to add stop words to delete. Since I didn’t need “coronavirus infection(코로나바이러스 감염증)”, I added them into the dictionary let delete them.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>add\_words &lt;- c("코로나바이러스 감염증")
buildDictionary(user\_dic = data.frame(add\_words, rep("ncn", length(add\_words))), replace\_usr\_dic = T)
</code></pre></div></div>

<h1 id="3-visualising">3 Visualising</h1>

<p>To explore the most frequently used top 10 keywords by period I created an interactive bubble chart with the drop-down list for filtering date ranges.</p>

<p>Normally word cloud are used to visualise words that appear the most frequently in the source. But my intention is compared keywords by period. The bubble chart with the drop-down list does the job better in such a case.</p>

<p><a href="https://public.flourish.studio/visualisation/2576893">English-language version of the bubble chart</a></p>

<div class="flourish-embed flourish-hierarchy" data-src="visualisation/2576893" data-url="https://flo.uri.sh/visualisation/2576893/embed"><script src="https://public.flourish.studio/resources/embed.js"></script></div>

<p>I created interactive bubble charts as well. You can see how I created them when you click the links below.
Which one do you like the most?</p>

<p><a href="https://codepen.io/looniii/pen/KKVPYQx">packed bubble chart</a>
<img src="https://user-images.githubusercontent.com/56850104/83661529-2ae15080-a5be-11ea-8a1e-e1e11909b2d6.png" alt="Screenshot 2020-06-03 at 17 14 02" /></p>

<p><a href="https://codepen.io/looniii/pen/YzwKMLp">split packed bubble chart</a>
<img src="https://user-images.githubusercontent.com/56850104/83661543-2e74d780-a5be-11ea-9dc8-3493db6cc4a5.png" alt="Screenshot 2020-06-03 at 17 15 35" /></p>

<h1 id="one-more-thing">One more thing</h1>

<p>Translating is an extra step in workflow for sharing the dataset with colleagues and tutors who speak different languages.</p>

<p>My initial plan was extracting more than 200 keywords each period to compare the main content of the news articles. Google translation API is a good option to translate a large amount of text.</p>

<p>I contacted engineers involved in making KoLNP to find a suitable machine translation for the Korean language.
Chel-Hee Lee, who is an adjunct assistant professor of University of Calgary in Canada, said;
“It may be a good idea to use GoogleLanguageR to translate into English. However, it is necessary to translate manually. Translation is a subjective matter at the end.”
He also said that natural language processing is a highly subjective matter.</p>

<p>I agree with him. Tools make you life easier, but you have to know how to use them.</p>

<hr />

<p><a href="https://www.bbc.com/korean/news-52601647">1</a> Naver is the leading portal site in Korea. Its news service Naver News(http://news.naver.com) is a news aggregator website that takes a large portion of news consumption in Korea. It currently sources content from 52 news outlets in real-time. The site stores the articles on its database and presents all of them on its website. It means being able to read all news articles in real-time from all major news outlets on one website in one standardised format. Therefore, it is the place for scraping news articles.</p>

<p><a href="https://public.flourish.studio/visualisation/2576893">2</a> N2H4 is the R package for Naver News Text Crawling. For more information, visit the website(https://github.com/forkonlp/N2H4)</p>



    
    

    
  </div>

</article>

</main>
<!-- Footer section -->

  <footer class="footer">
    <ul>
      <li><a href="/">Loonie Park</a></li>

      
        <li>
          <a href="https://sparanoid.com/lab/amsf/" title="Almace Scaffolding with theme Curtana">AMSF</a>
        </li>
      

      
    </ul>
  </footer>


<!-- Theme scripts -->
<script src="/assets/themes/curtana/js/app.js?assets-inline"></script>

<!-- User scripts -->
<script src="/assets/js/user.js?assets-inline"></script>

<!-- Lightense Images -->


<!-- Service Worker  -->


<!-- Google Analytics -->


<!-- Foot hooks -->


<!-- Finale -->
</html>
